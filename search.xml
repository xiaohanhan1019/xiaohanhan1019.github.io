<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Neural Network and Deep Learning (Week One)]]></title>
    <url>%2F2019%2F01%2F21%2FDeep-Learning-Week-One%2F</url>
    <content type="text"><![CDATA[1. Binary Classification (二分分类)在二分分类问题中，目标是训练出一个分类器，以特征向量x (feature vector)为输入，以y (output label)为输出，一般只有 ${0,1}$ 两个离散值。以图像识别问题为例，判断图片中是否由猫存在，0代表noncat，1代表cat 通常，我们用 $(x,y)$ 来表示一个单独的样本，其中x(feature vector)是$n_x$维的向量，y(output label)取值为 $y\in\{0,1\}$则m个训练样本 (training example) 可表示为 \{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\}用$ m=m_{train} ​$表示训练样本的个数 最后，用更紧凑的符号 $X​$ 表示整个训练集，$X​$ 由训练集中的 $x^{(1)}​$，$x^{(2)}​$，…，$x^{(m)}​$ 作为列向量组成，$X\in{\Bbb R}^{n_x*m}​$，即 X.shape = $(n_x,m)​$ \mathbf{X} = \left( \begin{array}{c} \vdots & \vdots & \ldots & \vdots \\\\ x^{(1)} & x^{(2)} & \ldots & x^{(m)} \\\\ \vdots & \vdots & \ldots & \vdots \end{array} \right)同时，把y标签也放入列中，用 $Y$ 来表示，$Y\in{\Bbb R}^{1*m}$，即 Y.shape = $(1,m) \mathbf{Y} = \left( \begin{array}{c} y^{(1)} & y^{(2)} & \ldots & y^{(m)} \ \end{array} \right)2. Logistic Regression (逻辑回归)逻辑回归是一种解决二分分类问题的机器学习方法，用于预测某种实物的可能性。 Given x, you want $\hat{y} = P(y=1 \mid x)$. In other words, if x is a picture, as talked about above, you want $\hat{y}$ to tell you the chance that there is a cat in the picture. 需要能根据输入 $x​$ 和参数 $w, b​$，计算出$\hat{y}​$ Parameter : $w\in{\Bbb R}^{n_x}, b\in{\Bbb R}$Output : $\hat{y}$ One way : $\hat{y} = w^{T}x + b​$ (Linear regression) Not good for binary classification Because you want $\hat{y}$ to be the chance that $y$ equals to one. In this situation $\hat{y}$ can be much bigger than 1 or negative. The other way : $\hat{y} = \sigma(w^{T}x + b)$ (Logistic Regression) $\sigma(z) = \frac{1}{1+e^{-z}} ​$ 通过$\sigma(z)$函数，可以将输出限定在$[0,1]$之间 3.Logistic Regression Cost Function (逻辑回归损失函数)给出$\{(x^{(1)},y^{(1)})…,(x^{(m)},y^{(m)})\}$，希望通过训练集，找到参数 $w, b$ 使得 $\hat{y}^{(i)} \approx y^{(i)}$ 。所以，我们需要定义一个loss function，通过这个loss function来衡量你的预测输出值 $\hat{y}$ 与 $y$ 的实际值由多接近 对于m个训练样本，我们通常用上标 $(i)$ 来指明数据与第 $i$ 个样本有关。 通常，我们这样定义Loss function (损失函数) : L(\hat{y},y) = \frac{1}{2}(\hat{y} - y)^2但在逻辑回归中一般不使用，因为它是non-convex (非凸的) ，将来使用梯度下降算法 (Gradient Descent)时无法找到全局最优值 在逻辑回归中，我们使用的损失函数为 : L(\hat{y},y) = -(y \log\hat{y} + (1-y) \log(1-\hat{y})) If y = 1 : $L(\hat{y},y) = -\log(\hat{y})​$, you want $\hat{y}​$ to be large if y = 0 : $L(\hat{y},y) = -\log(1-\hat{y})​$, you want $\hat{y}​$ to be small 所以，这个损失函数和 $L(\hat{y},y) = \frac{1}{2}(\hat{y} - y)^2$ 类似，都希望 $L$ 越小越好 上述的Loss function衡量了单个训练样本的表现，对于m个样本，我们定义Cost function (成本函数) ，它衡量了全体训练样本的表现 J(w,b) = \frac{1}{m} \sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)}) = -\frac{1}{m} \sum_{i=1}^{m}y^{(i)} \log\hat{y}^{(i)} + (1-y^{(i)}) \log(1-\hat{y}^{(i)})Loss function只适用于单个训练样本，Cost function是基于参数的总成本。所以，在训练逻辑回归模型时，我们要找到合适的参数 $w, b$ 使得Cost function尽可能的小 4.Gradient Descent (梯度下降)我们将使用梯度下降 (Gradient Descent) 算法来找出合适的参数 $w,b$，使得Cost function 即 $J(w,b)$ 最小 最上方的小红点为初始点，对于逻辑回归，一般使用0来初始化，随机初始化也有效，但通常不这么做 梯度下降过程： 从初始点开始，朝最陡的下坡方向走一步 重复上述过程，不断修正 $w, b​$ 使得 $J(w,b)​$ 接近全局最优值 (global opitmal) 代码表述为： Repeat {$w := w - \alpha \frac{\partial J(w,b)}{\partial w}$ &nbsp; &nbsp;&nbsp;&nbsp;在代码中 $\frac{\partial J(w,b)}{\partial w}$ 记作”dw”$b := b - \alpha \frac{\partial J(w,b)}{\partial b}$ &nbsp; &nbsp;&nbsp;&nbsp;在代码中 $\frac{\partial J(w,b)}{\partial b}​$ 记作”db”}]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java常量池]]></title>
    <url>%2F2019%2F01%2F17%2FJava-Constant-Pool%2F</url>
    <content type="text"><![CDATA[1. 常量池 相同的值只存储一份，节省内存，共享访问，提高运行效率 2.基本类型的包装类 Boolean Byte Short Integer Long Character Float Double 八种基本类型的包装类 常量值范围 Boolean：true, false Byte Character : \u0000 - \u007f Short Integer Long : -128 - 127 Float Double : 无常量池 3.==与equals() 对于基本数据类型，==比较他们的数值 对于对象，==比较两个对象在内存中的存放地址，可以通过重写equals()来比较两个对象的内容是否相等 4.字符串常量 Java为常量字符串建立了常量池缓存机制123456String s1 = "abc";String s2 = "ab" + "c";String s3 = "a" + "b" + "c"; //都是常量，是确定的，编译器将优化System.out.println(s1==s2); //trueSystem.out.println(s1==s3); //trueSystem.out.println(s2==s3); //true 5.基本类型的包装类和字符串的两种创建方式 字面值赋值，放在栈内存（将被常量化） Integer a = 1; String b = &quot;abc&quot;; new对象进行创建，放在堆内存（不会常量化） Integer c = new Integer(1); String d = new String(&quot;abc&quot;); 栈内存读取速度快，容量小 堆内存读取速度慢，容量大，可以通俗的理解为Java认为new出来的对象所占内存较大（不确定，而字面值是确定的），所以需要放在堆内存 6.Integer常量池的例子12345678910111213141516171819int i1 = 10;Integer i2 = 10; //自动装箱，10本来只是int，是基本类型，而我们需要把它变成一个对象，相当于包装了一层System.out.println(i1==i2) //true//自动拆箱 基本类型和包装类进行比较，包装类自动拆箱 Integer i3 = new Integer(10);System.out.println(i1==i3) //true 同理，包装类自动拆箱System.out.println(i2==i3) //false i2,i3都是对象，而i2是常量，在常量池，i3是new出来的对象，在堆内存中 Integer i4 = new Integer(5);Integer i5 = new Integer(5);System.out.println(i1 == (i4+i5)); //trueSystem.out.println(i1 == (i4+i5)); //trueSystem.out.println(i1 == (i4+i5)); //true//i4+i5的操作将会使i4,i5自动拆箱为基本类型并运算得到10，而根据之前所提到的，基本类型和包装类进行比较，包装类自动拆箱，所以都为trueInteger i6 = i4 + i5;System.out.println(i1==i6); //true，同理i4+i5的操作使i4,i5自动拆箱，得到10，相当于Integer i6 = 10;System.out.println(i3==i6); //false 7.String常量池的例子字符串常量池存在于方法区，方法区包含的都是在整个程序中唯一的元素，如static变量 一个简单的例子 1234567String s1 = "abc";String s2 = "abc";String s3 = new String("abc");String s4 = new String("abc");System.out.println(s1==s2); //true 都是常量池System.out.println(s1==s3); //false 一个是栈内存，一个是堆内存System.out.println(s3==s4); //false 都是堆内存，但是不同对象 图解：(&quot;由&#39;代替) graph LR; subgraph 方法区 s['abc'] end subgraph 堆 A["s3 = new String('abc')"] B["s4 = new String('abc')"] end subgraph 栈 s1 s2 s3 s4 end s1-->s s2-->s A-->s B-->s s3-->A s4-->B 更为复杂的例子123456789101112String s5 = "abcdef";String s6 = s1 + "def"; //涉及到变量（不确定的），编译器不会优化String s7 = "abc" + "def"; //都是常量，编译器会优化成abcdefString s8 = "abc" + new String("def"); //涉及到new对象，编译器不优化System.out.println(s6==s7); //falseSystem.out.println(s6==s8); //falseSystem.out.println(s7==s8); //falseSystem.out.println(s5==s7); //trueString s9 = s3 + "def"; //由于s3是new的，涉及到new对象，编译器不优化System.out.println(s7==s9); //false//对于s5~s9，只有s5,s7是在常量池中，其余都在堆内存上，且地址互不相同]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim Tutorial]]></title>
    <url>%2F2019%2F01%2F14%2FVim-Tutorial%2F</url>
    <content type="text"><![CDATA[This tutorial includes some basic vim commands and I hope that it will be helpful. 1.Moving the cursor h : left j : down k : up l : right It takes time to get used to it. 2.Navigation w: move the cursor one word forward (to the first letter) b : one word backward (also to the first letter) e : one word forward (to the last letter) fx : forward to the letter x ( : to the start of the sentence ) : start of the sentence 0 : start of line $ : end of line { : start of paragraph } : end of paragraph G : end of file ctrl+G : to see the cursor location and file status gg : start of file xG : to the number x line of file typing a number before a motion repeats it that many times! 3.Delete x: delete the character at the cursor dw: delete all the characters between the cursor and the first letter of the next word e.g. Please delete the word. (Assume the cursor is at l) After you press dw, the sentence becomes Please dethe word delete de: delete all the characters between the cursor and the next space e.g. Please delete the word. (Assume the cursor is at l) After you press de, the sentence becomes Please de the word delete d$ : delete to end of line dd : delete whole line p : After you delete something, press p to paste things you delete wherever you like. 4.Insert a : insert after the cursor A : insert after the end of line i : insert before the cursor I : insert before the start of line o : insert in the next line O : insert in the previous line 5.Search /yourSearchString + &lt;Enter&gt; : search for yourSearchString n : to search for the same string again (press &lt;Enter&gt; to exit) N : to search for the same string again, but in opposite direction ctrl+o : to go back to where you came from ctrl+i : to go forward set option :set ic : ignore case :set noic : disable ignore case :set hls : highlight the matches :set nohls : disable highlight matches :set is : increase search :set nois: disable increase search % : move the cursor to the other matching parenthesis 6.Replace rx : replace the character at cursor with x ce : almost the same as de, but this time will place you in Insert Mode s/old/new : replace the first occurrence of ‘old’ with ‘new’ s/old/new/g : replace all occurrence of ‘old’ with ‘new’ in one line #,#/old/new/g : #,# are the line numbers of the range of lines where the replace should be done %s/old/new/g : replace all occurrence of ‘old’ with ‘new’ in the whole file %s/old/new/g : replace all occurrence of ‘old’ with ‘new’ in the whole file, with a prompt whether to replace or not 7.Undo &amp; Redo u : undo the last command U : undo the command excuting on the while line ctrl+R : redo the command 8.Copy &amp; Paste y : to copy p : to paste e.g. Start Visual Mode with v and move the cursor to chose whatever you want, type y to copy the highlighted text and type p to paste the text. 9.Others . : repeat the last command &lt;start position&gt;&lt;command&gt;&lt;end position&gt; : many commands follow this pattern e.g. 0y$ means copy the whole line 0 move the cursor to the start of line y copy $ move the cursor to the end of line ctrl+n : auto complete]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
</search>
