<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" name="google-site-verification" content="4r262MlSHG2usfX6yLIYST-qBIOPGbPPczLRsjsatqY">
<title>Shallow Neural Networks-2 - xiaohanhan&#39;s blog</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <meta name="description" content="本文为 Andrew Ng 深度学习课程第一部分神经网络和深度学习的笔记，对应第三周浅层神经网络的相关课程及相关作业。 Why do you need non-linear activation function为什么神经网络需要非线性的激活函数？不能使用线性的激活函数，比如 $g(z) = z$ 吗？">
<meta name="keywords" content="Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Shallow Neural Networks-2">
<meta property="og:url" content="https://xiaohanhan1019.github.io/2019/02/01/Shallow-Neural-Networks-2/index.html">
<meta property="og:site_name" content="xiaohanhan&#39;s blog">
<meta property="og:description" content="本文为 Andrew Ng 深度学习课程第一部分神经网络和深度学习的笔记，对应第三周浅层神经网络的相关课程及相关作业。 Why do you need non-linear activation function为什么神经网络需要非线性的激活函数？不能使用线性的激活函数，比如 $g(z) = z$ 吗？">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://xiaohanhan1019.github.io/2019/02/01/Shallow-Neural-Networks-2/1.png">
<meta property="og:image" content="https://xiaohanhan1019.github.io/2019/02/01/Shallow-Neural-Networks-2/2.png">
<meta property="og:image" content="https://xiaohanhan1019.github.io/2019/02/01/Shallow-Neural-Networks-2/3.png">
<meta property="og:updated_time" content="2019-02-08T09:13:16.192Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Shallow Neural Networks-2">
<meta name="twitter:description" content="本文为 Andrew Ng 深度学习课程第一部分神经网络和深度学习的笔记，对应第三周浅层神经网络的相关课程及相关作业。 Why do you need non-linear activation function为什么神经网络需要非线性的激活函数？不能使用线性的激活函数，比如 $g(z) = z$ 吗？">
<meta name="twitter:image" content="https://xiaohanhan1019.github.io/2019/02/01/Shallow-Neural-Networks-2/1.png">





<link rel="icon" href="/images/avatar.png">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/xcode.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    

    
    
    
    

    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    


<link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="is-2-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                xiaohanhan
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">Home</a>
                
                <a class="navbar-item" href="/archives">Archives</a>
                
                <a class="navbar-item" href="/categories">Categories</a>
                
                <a class="navbar-item" href="/tags">Tags</a>
                
                <a class="navbar-item" href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-9-tablet is-9-desktop is-9-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-02-01T10:42:57.000Z">2019-02-01</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/deeplearning-ai/">deeplearning.ai</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/deeplearning-ai/Deep-learning-NN/">Deep learning & NN</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    23 minutes read (About 3383 words)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                Shallow Neural Networks-2
            
        </h1>
        <div class="content">
            <p>本文为 Andrew Ng 深度学习课程第一部分神经网络和深度学习的笔记，对应第三周浅层神经网络的相关课程及相关作业。</p>
<h3 id="Why-do-you-need-non-linear-activation-function"><a href="#Why-do-you-need-non-linear-activation-function" class="headerlink" title="Why do you need non-linear activation function"></a><strong>Why do you need non-linear activation function</strong></h3><p>为什么神经网络需要非线性的激活函数？不能使用线性的激活函数，比如 $g(z) = z$ 吗？</p>
<a id="more"></a>
<p>假设我们使用线性的激活函数 $g(z) = z$ ，那么有：</p>
<script type="math/tex; mode=display">
a^{[1]} = z^{[1]} = W^{[1]}x + b^{[1]}</script><script type="math/tex; mode=display">
a^{[2]} = z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}</script><p>把 $a^{[1]}$ 带入，则有</p>
<script type="math/tex; mode=display">
a^{[2]} = W^{[2]}(W^{[1]}x + b^{[1]}) + b^{[2]} = (W^{[2]}W{[1]})x + (W^{[2]}b^{[1]}+b{[2]}) = W'x+b'</script><p>我们可以得到，$a^{[2]}$ 仍是输入 $x$ 的线性组合。也就是说，使用线性函数的神经网络仅仅只是把输入 $x$ 线性组合再输出。即便是包含许多隐藏层的神经网络，如果使用的是线性的激活函数，不管多少层，得到的输出依然是 $x$ 的线性组合，也就意味着隐藏层根本没有什么作用。所以，隐藏层激活函数必须是非线性的，否则将失去意义。</p>
<p>只有一个地方你可能会使用线性激活函数，在机器学习的回归问题中，$y$ 是一个实数，比如你像预测房地产的价格，那么 $y$ 是一个实数，而不是像二分类问题那样要么 $0$ 要么 $1$ ，这种情况下，在输出层你可能会使用线性激活函数，但隐藏层不会使用线性激活函数。</p>
<h3 id="Derivatives-of-activation-functions"><a href="#Derivatives-of-activation-functions" class="headerlink" title="Derivatives of activation functions"></a><strong>Derivatives of activation functions</strong></h3><p>在反向传播的过程中，我们需要计算激活函数的导数，那么我们来看一下上述这些激活函数的导数。</p>
<ul>
<li>Sigmoid 函数<script type="math/tex; mode=display">
g(z) = \frac{1}{1+e^{-z}}</script></li>
</ul>
<script type="math/tex; mode=display">
g'(z) = g(z)(1-g(z)) = a(1-a)</script><ul>
<li>tanh 函数</li>
</ul>
<script type="math/tex; mode=display">
g(z) = \frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}</script><script type="math/tex; mode=display">
g'(z) = 1-(g(z))^{2} = 1-a^2</script><ul>
<li>ReLU 函数<script type="math/tex; mode=display">
g(z) = max(0,z)</script></li>
</ul>
<script type="math/tex; mode=display">
g'(z) = 
\begin{cases}
0,\quad z < 0 \\
1,\quad z \geq  0
\end{cases}</script><ul>
<li>Leaky ReLU 函数<script type="math/tex; mode=display">
g(z) = max(0.01z,z)</script></li>
</ul>
<script type="math/tex; mode=display">
g'(z) = \begin{cases}
0.01,\quad z < 0 \\\
1,\quad \quad z \geq  0
\end{cases}</script><h3 id="Gradient-descent-for-neural-networks"><a href="#Gradient-descent-for-neural-networks" class="headerlink" title="Gradient descent for neural networks"></a><strong>Gradient descent for neural networks</strong></h3><p>好了，有了以上的铺垫，我们终于可以实现在单隐藏层神经网络上的梯度下降算法了。</p>
<p>由于是单隐藏层神经网络，那么我们有参数 $W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]}​$ 。我们一般用 $n_x = n^{[0]}​$ 来表示输入层特征的个数，用 $n^{[1]}​$ 表示隐藏层节点个数，用 $n^{[2]}=1​$ 表示输出层节点个数。 其中，$W^{[1]}​$ 的维度为 $(n^{[1]}, n^{[0]})​$ ，$b^{[1]}​$ 的维度为 $(n^{[1]}, 1)​$ ，$W^{[2]}​$ 的维度为 $(n^{[2]}, n^{[1]})​$ ，$b^{[2]}​$ 的维度为 ​$(n^{[2]}, 1)​$ 。</p>
<p>假设我们在做二元分类，那么 Cost function 为：</p>
<script type="math/tex; mode=display">
J(W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]}) = \frac{1}{m}\sum_{i=1}^{m}L(\hat{y}, y)</script><p>整个训练神经网络的过程为：</p>
<blockquote>
<p>Repeat{</p>
<p>initialize parameters $W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]} $</p>
<p>compute predicts $\hat{y}^{(i)}, i \in [1,m]​$</p>
<p>compute $dW^{[1]}, db^{[1]}, W^{[2]}, b^{[2]}$</p>
<p>update $W^{[1]} = W^{[1]} - \alpha dW^{[1]}, b^{[1]} = b^{[1]} - \alpha db^{[1]} …​$  </p>
<p>}</p>
</blockquote>
<p>在训练神经网络时，随机初始化参数很重要，并不是单纯的全部初始化为 $0​$ ，我们将在后续详细讨论。</p>
<p>在之前，我们讨论了如果计算 predict (预测值) ，以及如何向量化实现整个过程，所以现在的关键在于，如何计算这些偏导项 $dW^{[1]}, db^{[1]}​$ … </p>
<p>神经网络正向传播的过程为：</p>
<script type="math/tex; mode=display">
Z^{[1]} = W^{[1]}X + b^{[1]}</script><script type="math/tex; mode=display">
A^{[1]} = g(Z^{[1]})</script><script type="math/tex; mode=display">
Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}</script><script type="math/tex; mode=display">
A^{[2]} = g(Z^{[2]}) = \sigma(Z^{[2]})</script><p>反向传播的过程为：</p>
<script type="math/tex; mode=display">
dZ^{[2]} = A^{[2]}-Y</script><script type="math/tex; mode=display">
dW^{[2]} = \frac{1}{m}dZ^{[2]}A^{[1]T}</script><script type="math/tex; mode=display">
db^{[2]} = \frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)</script><blockquote>
<p> 这个过程其实和之前的 Logistic Regression 很相似。需要注意的是，这里$db^{[2]}$ 的计算直接用了 python 语句，np.sum函数的参数 axis 代表在哪个维度上求和，keepdims为了保持 $db^{[2]}$ 的形状为 $(n^{[2]},1)$ 而不是奇怪的 $(n^{[2]}, )$ </p>
</blockquote>
<script type="math/tex; mode=display">
dZ^{[2]} = W^{[2]T}dZ^{[2]} * g^{[1]'}(Z^{[1]})</script><script type="math/tex; mode=display">
dW^{[1]} = \frac{1}{m}dZ^{[1]}X^{T}</script><script type="math/tex; mode=display">
db^{[1]}=\frac{1}{m}np.sum(dZ^{[1]},axis = 1,keepdims = True)</script><blockquote>
<p>需要注意的是 $dZ^{[2]} = W^{[2]T}dZ^{[2]} *g^{[1]’}(Z^{[1]})$ 这里是对应元素相乘，$W^{[2]T}dZ^{[2]}$ 的形状为 $(n^{[1]}, m)$ ，$g’^{[1]}(Z^{[1]})$ 的形状也为 $(n^{[1]}, m)$ 。</p>
</blockquote>
<p>关于详细的推导过程，会在接下来的部分详细说明。</p>
<h3 id="Backpropagation-intuition"><a href="#Backpropagation-intuition" class="headerlink" title="Backpropagation intuition"></a><strong>Backpropagation intuition</strong></h3><p>先回顾一下之前我们在实现 Logistic Regression 时是如何推导的，可以参考之前的博客 <a href="https://xiaohanhan1019.github.io/2019/01/21/Basic-of-Neural-Networks-1/">Logistic Regression Gradient Descent</a>.</p>
<p>由于现在多了一层隐藏层，整个反向传播过程会更复杂一点。</p>
<p>首先，先考虑单个样本的情况，先画出计算图，如下图：</p>
<p><img src="/2019/02/01/Shallow-Neural-Networks-2/1.png" alt=""></p>
<p>根据导数链式法则，可以计算出：</p>
<script type="math/tex; mode=display">
dz^{[2]} = \frac{\partial L}{\partial z^{[2]}} = \frac{\partial L}{\partial a^{[2]}} \cdot \frac{\partial a^{[2]}}{\partial z^{[2]}}= a^{[2]}-y</script><script type="math/tex; mode=display">
dW^{[2]}= \frac{\partial L}{\partial W^{[2]}} = \frac{\partial L}{\partial z^{[2]}} \cdot \frac{\partial z^{[2]}}{\partial W^{[2]}} = 
dz^{[2]} \cdot \frac{\partial z^{[2]}}{\partial W^{[2]}} = dz^{[2]}a^{[1]T}</script><blockquote>
<p>注意，这里 $dW^{[2]}$ 的形状为 $(n^{[2]}, n^{[1]})$ ， $n^{[1]}$ 为隐藏层节点个数，而 $a^{[1]}$ 形状为 $(n^{[1]}, n^{[2]})$ ，故这里需要 $a^{[1]}$ 转置，即 $a^{[1]T}$ 。</p>
</blockquote>
<script type="math/tex; mode=display">
db^{[2]}= \frac{\partial L}{\partial b^{[2]}} = \frac{\partial L}{\partial z^{[2]}} \cdot \frac{\partial z^{[2]}}{\partial b^{[2]}} = 
dz^{[2]} \cdot \frac{\partial z^{[2]}}{\partial b^{[2]}} = dz^{[2]}</script><script type="math/tex; mode=display">
dz^{[1]} = \frac{\partial L}{\partial z^{[1]}} = \frac{\partial L}{\partial a^{[1]}} \cdot \frac{\partial a^{[1]}}{\partial z^{[1]}} = \frac{\partial L}{\partial z^{[2]}} \cdot \frac{\partial z^{[2]}}{\partial a^{[1]}} \cdot \frac{\partial a^{[1]}}{\partial z^{[1]}} = dz^{[2]} \cdot \frac{\partial z^{[2]}}{\partial a^{[1]}} \cdot \frac{\partial a^{[1]}}{\partial z^{[1]}}</script><p>即，</p>
<script type="math/tex; mode=display">
dz^{[1]} = W^{[2]T}dz^{[2]} * g^{[1]'}(z^{[1]})</script><blockquote>
<p>同样，这里的 $W^{[2]T}$ 也需要转置，具体为什么，我也不是很明白，但可以从矩阵乘法的规则来判断其形状是否正确。需要注意的是，这里的乘法 $*$ 为对应元素相乘，而不是一般意义上的矩阵乘法。在实现过程中，你必须要确保矩阵的形状相匹配，这里 $W^{[2]T}$ 形状为 $(n^{[1]}, n^{[2]})$ ，$dz^{[2]}$ 的形状为 $(n^{[2]}, 1)$ ，$z^{[1]}$ 的形状为 $(n^{[1]}, 1)$</p>
</blockquote>
<script type="math/tex; mode=display">
dW^{[1]} = dz^{[1]} \cdot \frac{\partial z^{[1]}}{\partial W^{[1]}} = dz^{[1]}x^{T} = dz^{[1]}a^{[0]T}</script><script type="math/tex; mode=display">
db^{[1]} = dz^{[1]} \cdot \frac{\partial z^{[1]}}{\partial b^{[1]}} = dz^{[1]}</script><p>到这里为止，我们就推导完了反向传播的6个公式。接下来，我们需要将其推广到 $m$ 个训练样本的向量化实现上，得到结果如下，：</p>
<p><img src="/2019/02/01/Shallow-Neural-Networks-2/2.png" alt=""></p>
<h3 id="Random-Initialization"><a href="#Random-Initialization" class="headerlink" title="Random Initialization"></a><strong>Random Initialization</strong></h3><p>神经网络中的参数 $W$ 是不能和 Logistic Regression 那样全部初始化为 $0$ 的，我们来分析一下原因。</p>
<p>假设我们有这样一个神经网络，如下图所示：</p>
<p><img src="/2019/02/01/Shallow-Neural-Networks-2/3.png" alt=""></p>
<p>假设，我们将 $W^{[1]}, W^{[2]}$ 都初始化为零矩阵，那么经过正向传播以后，我们会得到 $a^{[1]}_1 = a^{[1]}_{2}$ ，那么根据对称性，在反向传播后会有 $dz^{[1]}_{1} = dz^{[1]}_{2}$ ， $dW^{[1]}_{1}=dW^{[1]}_{2}$ ，无论你执行多少次梯度下降算法，隐藏层的每个节点都在做相同的操作。这样的话，最后我们获得的 $W^{[1]}, W^{[2]}$ 每行元素都相同，也就是说所有隐藏层中的节点都可以用一个节点来代替，多余的节点没有任何意义，这不是我们想要的。 另外，参数 $b$ 可以全部初始化为 $0$ ，不会发生上面提到的问题。</p>
<p>所以，我们必须随机初始化所有的参数。python 语句如下：</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W1 = np.random.randn((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>))*<span class="hljs-number">0.01</span></span><br><span class="line">b1 = np.zero((<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))</span><br><span class="line">W1 = np.random.randn((<span class="hljs-number">1</span>,<span class="hljs-number">2</span>))*<span class="hljs-number">0.01</span></span><br><span class="line">b1 = <span class="hljs-number">0</span></span><br></pre></td></tr></table></figure>
<p>你可能为由疑问，为什么这里要 $*0.01$ ，为什么是 $0.01$ 而不是其他的数字？事实上，我们倾向于把矩阵初始化为非常非常小的随机值。因为如果你用 tanh 函数或者 sigmoid 函数作为激活函数， $W$ 比较小，那正向传播后得到的 $z$ 也会比较小，经过激活函数后所得到的 $a$ 也会接近于 $0$ ，而在 $0$ 附近，激活函数的斜率比较大，能大大地提高梯度下降算法的更新速度，即学习的速度。如果你使用的激活函数为 ReLU 或是 Leaky ReLU 则没有这个问题。</p>
<p>有时候，会有比 $0.01$ 更好用的常数，但如果你只是训练一个单隐层神经网络，或是一个相对较浅的神经网络，没有太多隐藏层，使用 $0.01$ 没有太大问题。但是当你训练一个很深的神经网络时，你可能需要尝试一下别的常数，关于常数的详细内容会在后续部分提到。</p>
<h3 id="Homework"><a href="#Homework" class="headerlink" title="Homework"></a><strong>Homework</strong></h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Package imports</span></span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"><span class="hljs-keyword">from</span> testCases_v2 <span class="hljs-keyword">import</span> *</span><br><span class="line"><span class="hljs-keyword">import</span> sklearn</span><br><span class="line"><span class="hljs-keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="hljs-keyword">import</span> sklearn.linear_model</span><br><span class="line"><span class="hljs-keyword">from</span> planar_utils <span class="hljs-keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">layer_sizes</span><span class="hljs-params">(X, Y)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Arguments:</span></span><br><span class="line"><span class="hljs-string">    X -- input dataset of shape (input size, number of examples)</span></span><br><span class="line"><span class="hljs-string">    Y -- labels of shape (output size, number of examples)</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    n_x -- the size of the input layer</span></span><br><span class="line"><span class="hljs-string">    n_h -- the size of the hidden layer</span></span><br><span class="line"><span class="hljs-string">    n_y -- the size of the output layer</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    n_x = X.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># size of input layer</span></span><br><span class="line">    n_h = <span class="hljs-number">4</span></span><br><span class="line">    n_y = Y.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># size of output layer</span></span><br><span class="line">    <span class="hljs-keyword">return</span> (n_x, n_h, n_y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initialize_parameters</span><span class="hljs-params">(n_x, n_h, n_y)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Argument:</span></span><br><span class="line"><span class="hljs-string">    n_x -- size of the input layer</span></span><br><span class="line"><span class="hljs-string">    n_h -- size of the hidden layer</span></span><br><span class="line"><span class="hljs-string">    n_y -- size of the output layer</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    params -- python dictionary containing your parameters:</span></span><br><span class="line"><span class="hljs-string">                    W1 -- weight matrix of shape (n_h, n_x)</span></span><br><span class="line"><span class="hljs-string">                    b1 -- bias vector of shape (n_h, 1)</span></span><br><span class="line"><span class="hljs-string">                    W2 -- weight matrix of shape (n_y, n_h)</span></span><br><span class="line"><span class="hljs-string">                    b2 -- bias vector of shape (n_y, 1)</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="hljs-number">2</span>)  <span class="hljs-comment"># we set up a seed so that your output matches ours although the initialization is random.</span></span><br><span class="line"></span><br><span class="line">    W1 = np.random.randn(n_h, n_x) * <span class="hljs-number">0.01</span></span><br><span class="line">    b1 = np.zeros((n_h, <span class="hljs-number">1</span>))</span><br><span class="line">    W2 = np.random.randn(n_y, n_h) * <span class="hljs-number">0.01</span></span><br><span class="line">    b2 = np.zeros((n_y, <span class="hljs-number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">assert</span> (W1.shape == (n_h, n_x))</span><br><span class="line">    <span class="hljs-keyword">assert</span> (b1.shape == (n_h, <span class="hljs-number">1</span>))</span><br><span class="line">    <span class="hljs-keyword">assert</span> (W2.shape == (n_y, n_h))</span><br><span class="line">    <span class="hljs-keyword">assert</span> (b2.shape == (n_y, <span class="hljs-number">1</span>))</span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="hljs-string">"W1"</span>: W1,</span><br><span class="line">                  <span class="hljs-string">"b1"</span>: b1,</span><br><span class="line">                  <span class="hljs-string">"W2"</span>: W2,</span><br><span class="line">                  <span class="hljs-string">"b2"</span>: b2&#125;</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward_propagation</span><span class="hljs-params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Argument:</span></span><br><span class="line"><span class="hljs-string">    X -- input data of size (n_x, m)</span></span><br><span class="line"><span class="hljs-string">    parameters -- python dictionary containing your parameters (output of initialization function)</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    A2 -- The sigmoid output of the second activation</span></span><br><span class="line"><span class="hljs-string">    cache -- a dictionary containing "Z1", "A1", "Z2" and "A2"</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    <span class="hljs-comment"># Retrieve each parameter from the dictionary "parameters"</span></span><br><span class="line">    W1 = parameters[<span class="hljs-string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="hljs-string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="hljs-string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="hljs-string">"b2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Implement Forward Propagation to calculate A2 (probabilities)</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = np.tanh(Z1)</span><br><span class="line">    Z2 = np.dot(W2, A1) + b2</span><br><span class="line">    A2 = sigmoid(Z2)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">assert</span> (A2.shape == (<span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>]))</span><br><span class="line"></span><br><span class="line">    cache = &#123;<span class="hljs-string">"Z1"</span>: Z1,</span><br><span class="line">             <span class="hljs-string">"A1"</span>: A1,</span><br><span class="line">             <span class="hljs-string">"Z2"</span>: Z2,</span><br><span class="line">             <span class="hljs-string">"A2"</span>: A2&#125;</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> A2, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_cost</span><span class="hljs-params">(A2, Y, parameters)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Computes the cross-entropy cost given in equation (13)</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Arguments:</span></span><br><span class="line"><span class="hljs-string">    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)</span></span><br><span class="line"><span class="hljs-string">    Y -- "true" labels vector of shape (1, number of examples)</span></span><br><span class="line"><span class="hljs-string">    parameters -- python dictionary containing your parameters W1, b1, W2 and b2</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    cost -- cross-entropy cost given equation (13)</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line"></span><br><span class="line">    m = Y.shape[<span class="hljs-number">1</span>]  <span class="hljs-comment"># number of example</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Compute the cross-entropy cost</span></span><br><span class="line">    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(<span class="hljs-number">1</span> - A2), <span class="hljs-number">1</span> - Y)</span><br><span class="line">    cost = -np.sum(logprobs) / m</span><br><span class="line"></span><br><span class="line">    cost = np.squeeze(cost)  <span class="hljs-comment"># makes sure cost is the dimension we expect.</span></span><br><span class="line">    <span class="hljs-comment"># E.g., turns [[17]] into 17</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> (isinstance(cost, float))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> cost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward_propagation</span><span class="hljs-params">(parameters, cache, X, Y)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Implement the backward propagation using the instructions above.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Arguments:</span></span><br><span class="line"><span class="hljs-string">    parameters -- python dictionary containing our parameters</span></span><br><span class="line"><span class="hljs-string">    cache -- a dictionary containing "Z1", "A1", "Z2" and "A2".</span></span><br><span class="line"><span class="hljs-string">    X -- input data of shape (2, number of examples)</span></span><br><span class="line"><span class="hljs-string">    Y -- "true" labels vector of shape (1, number of examples)</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    grads -- python dictionary containing your gradients with respect to different parameters</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    m = X.shape[<span class="hljs-number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># First, retrieve W1 and W2 from the dictionary "parameters".</span></span><br><span class="line">    W1 = parameters[<span class="hljs-string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="hljs-string">"W2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Retrieve also A1 and A2 from dictionary "cache".</span></span><br><span class="line">    A1 = cache[<span class="hljs-string">"A1"</span>]</span><br><span class="line">    A2 = cache[<span class="hljs-string">"A2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Backward propagation: calculate dW1, db1, dW2, db2.</span></span><br><span class="line">    dZ2 = A2 - Y</span><br><span class="line">    dW2 = np.dot(dZ2, A1.T) / m</span><br><span class="line">    db2 = np.sum(dZ2, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>) / m</span><br><span class="line">    dZ1 = np.dot(W2.T, dZ2) * (<span class="hljs-number">1</span> - np.power(A1, <span class="hljs-number">2</span>))</span><br><span class="line">    dW1 = np.dot(dZ1, X.T) / m</span><br><span class="line">    db1 = np.sum(dZ1, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>) / m</span><br><span class="line"></span><br><span class="line">    grads = &#123;<span class="hljs-string">"dW1"</span>: dW1,</span><br><span class="line">             <span class="hljs-string">"db1"</span>: db1,</span><br><span class="line">             <span class="hljs-string">"dW2"</span>: dW2,</span><br><span class="line">             <span class="hljs-string">"db2"</span>: db2&#125;</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> grads</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_parameters</span><span class="hljs-params">(parameters, grads, learning_rate=<span class="hljs-number">1.2</span>)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Updates parameters using the gradient descent update rule given above</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Arguments:</span></span><br><span class="line"><span class="hljs-string">    parameters -- python dictionary containing your parameters</span></span><br><span class="line"><span class="hljs-string">    grads -- python dictionary containing your gradients</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    parameters -- python dictionary containing your updated parameters</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    <span class="hljs-comment"># Retrieve each parameter from the dictionary "parameters"</span></span><br><span class="line">    W1 = parameters[<span class="hljs-string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="hljs-string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="hljs-string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="hljs-string">"b2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Retrieve each gradient from the dictionary "grads"</span></span><br><span class="line">    dW1 = grads[<span class="hljs-string">"dW1"</span>]</span><br><span class="line">    db1 = grads[<span class="hljs-string">"db1"</span>]</span><br><span class="line">    dW2 = grads[<span class="hljs-string">"dW2"</span>]</span><br><span class="line">    db2 = grads[<span class="hljs-string">"db2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Update rule for each parameter</span></span><br><span class="line">    W1 = W1 - learning_rate * dW1</span><br><span class="line">    b1 = b1 - learning_rate * db1</span><br><span class="line">    W2 = W2 - learning_rate * dW2</span><br><span class="line">    b2 = b2 - learning_rate * db2</span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="hljs-string">"W1"</span>: W1,</span><br><span class="line">                  <span class="hljs-string">"b1"</span>: b1,</span><br><span class="line">                  <span class="hljs-string">"W2"</span>: W2,</span><br><span class="line">                  <span class="hljs-string">"b2"</span>: b2&#125;</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nn_model</span><span class="hljs-params">(X, Y, n_h, num_iterations=<span class="hljs-number">10000</span>, print_cost=False)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Arguments:</span></span><br><span class="line"><span class="hljs-string">    X -- dataset of shape (2, number of examples)</span></span><br><span class="line"><span class="hljs-string">    Y -- labels of shape (1, number of examples)</span></span><br><span class="line"><span class="hljs-string">    n_h -- size of the hidden layer</span></span><br><span class="line"><span class="hljs-string">    num_iterations -- Number of iterations in gradient descent loop</span></span><br><span class="line"><span class="hljs-string">    print_cost -- if True, print the cost every 1000 iterations</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns:</span></span><br><span class="line"><span class="hljs-string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="hljs-number">3</span>)</span><br><span class="line">    n_x = layer_sizes(X, Y)[<span class="hljs-number">0</span>]</span><br><span class="line">    n_y = layer_sizes(X, Y)[<span class="hljs-number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: "n_x, n_h, n_y". Outputs = "W1, b1, W2, b2, parameters".</span></span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">    W1 = parameters[<span class="hljs-string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="hljs-string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="hljs-string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="hljs-string">"b2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Loop (gradient descent)</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Forward propagation. Inputs: "X, parameters". Outputs: "A2, cache".</span></span><br><span class="line">        A2, cache = forward_propagation(X, parameters)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Cost function. Inputs: "A2, Y, parameters". Outputs: "cost".</span></span><br><span class="line">        cost = compute_cost(A2, Y, parameters)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Backpropagation. Inputs: "parameters, cache, X, Y". Outputs: "grads".</span></span><br><span class="line">        grads = backward_propagation(parameters, cache, X, Y)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Gradient descent parameter update. Inputs: "parameters, grads". Outputs: "parameters".</span></span><br><span class="line">        parameters = update_parameters(parameters, grads)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Print the cost every 1000 iterations</span></span><br><span class="line">        <span class="hljs-keyword">if</span> print_cost <span class="hljs-keyword">and</span> i % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">            print(<span class="hljs-string">"Cost after iteration %i: %f"</span> % (i, cost))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(parameters, X)</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Using the learned parameters, predicts a class for each example in X</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Arguments:</span></span><br><span class="line"><span class="hljs-string">    parameters -- python dictionary containing your parameters</span></span><br><span class="line"><span class="hljs-string">    X -- input data of size (n_x, m)</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    Returns</span></span><br><span class="line"><span class="hljs-string">    predictions -- vector of predictions of our model (red: 0 / blue: 1)</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.</span></span><br><span class="line">    A2, cache = forward_propagation(X, parameters)</span><br><span class="line">    predictions = (A2 &gt; <span class="hljs-number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span></span><br><span class="line">    <span class="hljs-comment"># random seed</span></span><br><span class="line">    np.random.seed(<span class="hljs-number">1</span>)  <span class="hljs-comment"># set a seed so that the results are consistent</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Load data</span></span><br><span class="line">    X, Y = load_planar_dataset()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Visualize the data</span></span><br><span class="line">    <span class="hljs-comment"># 原来的代码会报错，同样planar_utils.py 21行也需要修改</span></span><br><span class="line">    plt.scatter(X[<span class="hljs-number">0</span>, :], X[<span class="hljs-number">1</span>, :], c=Y.reshape(X[<span class="hljs-number">0</span>, :].shape), cmap=plt.cm.Spectral)</span><br><span class="line">    <span class="hljs-comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># shape of dataset</span></span><br><span class="line">    shape_X = X.shape</span><br><span class="line">    shape_Y = Y.shape</span><br><span class="line">    m = X.shape[<span class="hljs-number">1</span>]  <span class="hljs-comment"># training set size</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Build a model with a n_h-dimensional hidden layer</span></span><br><span class="line">    parameters = nn_model(X, Y, n_h=<span class="hljs-number">4</span>, num_iterations=<span class="hljs-number">10000</span>, print_cost=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Plot the decision boundary</span></span><br><span class="line">    plot_decision_boundary(<span class="hljs-keyword">lambda</span> x: predict(parameters, x.T), X, Y)</span><br><span class="line">    plt.title(<span class="hljs-string">"Decision Boundary for hidden layer size "</span> + str(<span class="hljs-number">4</span>))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Print accuracy</span></span><br><span class="line">    predictions = predict(parameters, X)</span><br><span class="line">    print(<span class="hljs-string">'Accuracy: %d'</span> % float(</span><br><span class="line">        (np.dot(Y, predictions.T) + np.dot(<span class="hljs-number">1</span> - Y, <span class="hljs-number">1</span> - predictions.T)) / float(Y.size) * <span class="hljs-number">100</span>) + <span class="hljs-string">'%'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># # Train the logistic regression classifier</span></span><br><span class="line">    <span class="hljs-comment"># clf = sklearn.linear_model.LogisticRegressionCV()</span></span><br><span class="line">    <span class="hljs-comment"># clf.fit(X.T, Y.T)</span></span><br><span class="line">    <span class="hljs-comment">#</span></span><br><span class="line">    <span class="hljs-comment"># # Plot the decision boundary for logistic regression</span></span><br><span class="line">    <span class="hljs-comment"># plot_decision_boundary(lambda x: clf.predict(x), X, Y)</span></span><br><span class="line">    <span class="hljs-comment"># plt.title("Logistic Regression")</span></span><br><span class="line">    <span class="hljs-comment"># plt.show()</span></span><br><span class="line">    <span class="hljs-comment">#</span></span><br><span class="line">    <span class="hljs-comment"># # Print accuracy</span></span><br><span class="line">    <span class="hljs-comment"># LR_predictions = clf.predict(X.T)</span></span><br><span class="line">    <span class="hljs-comment"># print('Accuracy of logistic regression: %d ' % float(</span></span><br><span class="line">    <span class="hljs-comment">#     (np.dot(Y, LR_predictions) + np.dot(1 - Y, 1 - LR_predictions)) / float(Y.size) * 100) +</span></span><br><span class="line">    <span class="hljs-comment">#       '% ' + "(percentage of correctly labelled datapoints)")</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/Deep-Learning/">Deep Learning</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2019/02/08/Deep-Neural-Networks-1/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">Deep Neural Networks-1</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2019/02/01/Shallow-Neural-Networks-1/">
                <span class="level-item">Shallow Neural Networks-1</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                




<div class="column is-3-tablet is-3-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered">
                <div>
                    <img class="image is-128x128 has-mb-6" src="/images/avatar.png" alt="Zihan Song">
                    
                    <p class="is-size-4 is-block">
                        Zihan Song
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        Developer
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Shanghai, China</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <p class="title has-text-weight-normal">
                        12
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <p class="title has-text-weight-normal">
                        6
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <p class="title has-text-weight-normal">
                        4
                    </p>
                </div>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="http://github.com/xiaohanhan1019">
                Follow</a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Github" href="http://github.com/xiaohanhan1019">
                
                <i class="fab fa-github"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
<div class="card widget" id="toc">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Catalogue
            </h3>
            <ul class="menu-list"><li>
        <a class="is-flex" href="#Why-do-you-need-non-linear-activation-function">
        <span class="has-mr-6">1</span>
        <span>Why do you need non-linear activation function</span>
        </a></li><li>
        <a class="is-flex" href="#Derivatives-of-activation-functions">
        <span class="has-mr-6">2</span>
        <span>Derivatives of activation functions</span>
        </a></li><li>
        <a class="is-flex" href="#Gradient-descent-for-neural-networks">
        <span class="has-mr-6">3</span>
        <span>Gradient descent for neural networks</span>
        </a></li><li>
        <a class="is-flex" href="#Backpropagation-intuition">
        <span class="has-mr-6">4</span>
        <span>Backpropagation intuition</span>
        </a></li><li>
        <a class="is-flex" href="#Random-Initialization">
        <span class="has-mr-6">5</span>
        <span>Random Initialization</span>
        </a></li><li>
        <a class="is-flex" href="#Homework">
        <span class="has-mr-6">6</span>
        <span>Homework</span>
        </a></li></ul>
        </div>
    </div>
</div>

    
        


    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/Java/">
            <span class="level-start">
                <span class="level-item">Java</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Software-Engineering/">
            <span class="level-start">
                <span class="level-item">Software Engineering</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Software-Engineering/Object-Oriented/">
            <span class="level-start">
                <span class="level-item">Object-Oriented</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/deeplearning-ai/">
            <span class="level-start">
                <span class="level-item">deeplearning.ai</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/deeplearning-ai/Deep-learning-NN/">
            <span class="level-start">
                <span class="level-item">Deep learning & NN</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/vim/">
            <span class="level-start">
                <span class="level-item">vim</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Object-Oriented/" style="font-size: 15px;">Object-Oriented</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a>
    </div>
</div>

    
    
        <!-- 主页三栏，Post页两栏-->
        <!-- <div class="column-right-shadow is-hidden-widescreen "> -->
        <div class="column-right-shadow  ">
        
            
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2019/02/19/Object-Oriented-4/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-4">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-19T01:28:48.000Z">2019-02-19</time></div>
                    <a href="/2019/02/19/Object-Oriented-4/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-4</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/17/Object-Oriented-3/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-3">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-17T06:30:53.000Z">2019-02-17</time></div>
                    <a href="/2019/02/17/Object-Oriented-3/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-3</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/17/Object-Oriented-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-17T02:37:18.000Z">2019-02-17</time></div>
                    <a href="/2019/02/17/Object-Oriented-2/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/16/Object-Oriented-1/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-1">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-16T08:58:22.000Z">2019-02-16</time></div>
                    <a href="/2019/02/16/Object-Oriented-1/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-1</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/08/Deep-Neural-Networks-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Deep Neural Networks-2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-08T09:11:34.000Z">2019-02-08</time></div>
                    <a href="/2019/02/08/Deep-Neural-Networks-2/" class="has-link-black-ter is-size-6">Deep Neural Networks-2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/deeplearning-ai/">deeplearning.ai</a> / <a class="has-link-grey -link" href="/categories/deeplearning-ai/Deep-learning-NN/">Deep learning & NN</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2019/02/">
                <span class="level-start">
                    <span class="level-item">February 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">8</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">January 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <ul class="menu-list">
                
                <li>
                    <a class="level is-marginless" href="/tags/Deep-Learning/">
                        <span class="level-start">
                            <span class="level-item">Deep Learning</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">6</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Java/">
                        <span class="level-start">
                            <span class="level-item">Java</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Object-Oriented/">
                        <span class="level-start">
                            <span class="level-item">Object-Oriented</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">4</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/vim/">
                        <span class="level-start">
                            <span class="level-item">vim</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                <!-- 




<div class="column is-3-tablet is-3-desktop is-3-widescreen  has-order-3 column-right ">
    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2019/02/19/Object-Oriented-4/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-4">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-19T01:28:48.000Z">2019-02-19</time></div>
                    <a href="/2019/02/19/Object-Oriented-4/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-4</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/17/Object-Oriented-3/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-3">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-17T06:30:53.000Z">2019-02-17</time></div>
                    <a href="/2019/02/17/Object-Oriented-3/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-3</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/17/Object-Oriented-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-17T02:37:18.000Z">2019-02-17</time></div>
                    <a href="/2019/02/17/Object-Oriented-2/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/16/Object-Oriented-1/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Objected-Oriented Analysis and Design-1">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-16T08:58:22.000Z">2019-02-16</time></div>
                    <a href="/2019/02/16/Object-Oriented-1/" class="has-link-black-ter is-size-6">Objected-Oriented Analysis and Design-1</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Software-Engineering/">Software Engineering</a> / <a class="has-link-grey -link" href="/categories/Software-Engineering/Object-Oriented/">Object-Oriented</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/02/08/Deep-Neural-Networks-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Deep Neural Networks-2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-02-08T09:11:34.000Z">2019-02-08</time></div>
                    <a href="/2019/02/08/Deep-Neural-Networks-2/" class="has-link-black-ter is-size-6">Deep Neural Networks-2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/deeplearning-ai/">deeplearning.ai</a> / <a class="has-link-grey -link" href="/categories/deeplearning-ai/Deep-learning-NN/">Deep learning & NN</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2019/02/">
                <span class="level-start">
                    <span class="level-item">February 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">8</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">January 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <ul class="menu-list">
                
                <li>
                    <a class="level is-marginless" href="/tags/Deep-Learning/">
                        <span class="level-start">
                            <span class="level-item">Deep Learning</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">6</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Java/">
                        <span class="level-start">
                            <span class="level-item">Java</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Object-Oriented/">
                        <span class="level-start">
                            <span class="level-item">Object-Oriented</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">4</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/vim/">
                        <span class="level-start">
                            <span class="level-item">vim</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>
    
    
</div>
 -->
                <!-- 主页三栏，post页两栏 -->
                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    xiaohanhan
                
                </a>
                <p class="is-size-7">
                &copy; 2019 xiaohanhan&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a href="http://github.com/ppoffice/hexo-theme-icarus">Icarus</a>
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>


  <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'default'});
    }
  </script>


    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {matchFontHeight: false},
        SVG: {matchFontHeight: false},
        CommonHTML: {matchFontHeight: false}
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    

    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>